{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feba84ac",
   "metadata": {},
   "source": [
    "# Fundamentals of Social Data Science 2025. Week 1. Day 2. Exercises\n",
    "\n",
    "This is a group assignment. \n",
    "\n",
    "You will be expected to submit an individual assignment on Tuesday at 12pm (not Monday) on Canvas. The sheet that you will be expected to submit will be released on Friday at 12pm. It is submitted on Tuesday because you will want to integrate your materials post-presentation. \n",
    "\n",
    "- That sheet will have a small number of individual questions related to Friday's assignment\n",
    "- It will include one question about your presentation. That question is reproduced below so there are no surprises. \n",
    "\n",
    "The assignment submission details will be posted on Canvas under assignments.\n",
    "\n",
    "To itemise: \n",
    "- Week 1. Day 2. Wednesday at 12pm: This \"getting started\" sheet is released. \n",
    "- Wednesday afternoon tutorial: We will want to ensure that you can get started on loading data. \n",
    "- Week 1. Day 3. Friday at 12pm: The individual assignment is released. \n",
    "- Week 1. Day 3. Friday afternoon tutorial: You will want to play with the Claude artifact as well as continue working with your group. \n",
    "- Week 2. Day 1. Monday at 12pm: An exercise will be released related to Network Canvas. It will require you to download Network Canvas interviewer from networkcanvas.com. \n",
    "- Week 2. Day 1. Monday afternoon tutorial: Bernie will explain the Network Canvas exercise as a part of the class. The tutorial period will be group presentations. \n",
    "- Tuesday at 12pm: Your individual assignment is due. \n",
    "- Tuesday at 12pm: Your group assignment should be posted. \n",
    "\n",
    "> **NOTE:** This assignment will use data from the web. This assignment has NOT been cleared for research via the CUREC process. It is an in-class assignment. Therefore, if you wish to publish anything from this analysis, you must first apply for a CUREC before publishing anything publicly with your Oxford affiliation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404f3cb",
   "metadata": {},
   "source": [
    "# Group exercise: Getting started\n",
    "\n",
    "The group assignment will make use of the StackDownloader from the FSSTDS repository. This downloader (recently tested) will download, extract and process a StackExchange archive. It is pretty close to 'one click'. It creates a 'feather' archive, which is a very nice format for compressing DataFrames. You can open this in your own code. \n",
    "\n",
    "To begin, you will need to have everything installed for the StackDownloader. How do we do that? We install the requirements.\n",
    "\n",
    "- **Step 1.** Clone the FSSTDS repository. \n",
    "- **Step 2.** Open the Ch.00.Stack_downloader and 'select kernel', select \"Python Environments...\", \"Create Python Environment\", \"Venv -> Creates a `.venv` virtual environment in the current workspace\", select **Python 3.12**. Note 3.14 is untested. Select dependencies to install -> requirements.txt. \n",
    "- **Step 3.** Run the big code cell in Stack_downloader. Select a specific archive. \n",
    "- **Step 4.** Locate and load the DataFrame. You can now use the Stack Exchange in your work. \n",
    "\n",
    "Note if you get errors with PyArrow below, try restarting the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ac8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case this Jupyter Notebook is in a different repo than FSSTDS, you may need to install\n",
    "# pandas and pyarrow to parse the file. \n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pandas\", \"pyarrow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q0. Check that you can load your own DataFrame\n",
    " \n",
    "import pandas as pd \n",
    "\n",
    "stack_df = df = pd.read_feather('/Users/berniehogan/teaching/FSDS25/fsstds/data/ai.stackexchange.com/Posts.feather')\n",
    "\n",
    "print(stack_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dce78f",
   "metadata": {},
   "source": [
    "# Q1. Navigating the data. \n",
    "\n",
    "Let's begin with some exploratory data analysis. Despite being a group assignment, you should individually be able to accomplish the following. \n",
    "\n",
    "1. The data contains different post types. How many questions and how many answers? Try: `display(stack_df['PostTypeId'].value_counts())` \n",
    "2. How many users are in this data set? \n",
    "3. What is the average score of the user?\n",
    "4. What is the average number of comments for the users?\n",
    "5. Plot the distribution of the number of comments by user. Is it normally distributed?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers to Q1.1...Q1.5 \n",
    "# (Unsubmitted; merely for practice and preparation; \n",
    "# every student should be able to do this themselves. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7c44f",
   "metadata": {},
   "source": [
    "## Q2. Defining helpfulness \n",
    "\n",
    "If you can describe the data simply then you are on your way to the big question for the group. Recall two of the trade-offs from the last lecture: \"operationalisation\" and \"coding\". The group project this week is very simple in some senses and very complex in other senses: \n",
    "\n",
    "Two questions: \n",
    "> - \"How can we identify the most helpful users in this space\" \n",
    "> - \"When were the helpful users the most helpful or most active?\"\n",
    "\n",
    "So this means that your group will have to discuss:\n",
    "- What defines helpfulness? Are there multiple possible metrics? \n",
    "- Do we think that a helpful person should _always_ be helpful? \n",
    "- Is helpfulness topic-specific? \n",
    "- You may want to explore wrangling the data by time. \n",
    "\n",
    "We do not expect you to merge in data from the users.xml / users.feather for this. However, you may want to explore how to create a datatime column. This is not covered in this lecture, but you may want to read either Chapter 10 of FSSTDS on cleaning data and Chapter 12 of FSSTDS on wrangling time data. \n",
    "\n",
    "You will want to divide some tasks among your group. Some might be delegated to surf the space online to come up with abductive hypotheses. Some might want to focus on rendering some charts. Some might be excellent at presentation design or at presenting to the group. Lean into your expertise and collaborate.\n",
    "\n",
    "Presentations for this will be on Monday afternoon. The presentations will be no more than 12 minutes + 3 minutes of questions & transition. \n",
    "\n",
    "Each group will have a 'space' on Canvas to submit 3 things: \n",
    "- the presentation \n",
    "- the code\n",
    "- the 'credits'. A single sheet (in docx/md) that details which group members participated in which ways. Treat this not merely as accountability but an opportunity to signal your own strengths. We do not expect everyone to do 1/5 of the work for every task. We do expect everyone to contribute in some way.\n",
    "\n",
    "This code will not be graded but it will be made available to other students. \n",
    "The presentations will be given short written feedback by the instructor post-presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36527785",
   "metadata": {},
   "source": [
    "# Q3. Your individual submission \n",
    "\n",
    "Your individual submission on Week 2 (from the sheet to be shared on Friday) will have two broad questions. One of these will be related to the Claude artifact that will be shared on Friday. The other will be related to this work. The question will be on the Friday assignment's sheet so you do not have to submit two sheets. It is posted here so you can see where we are going. \n",
    "\n",
    "## Defining helpfulness \n",
    "\n",
    "Describe two different ways of operationalising helpfulness. Report on these with descriptive statistics. One of these should be the form of helpfulness that is discussed in the group presentation. One should be a version that you have determined individually. It does need to not be complicated. Articulate the difference between these two interpretations of helpfulness and why you might opt for one over the other in some circumstance. Use evidence derived from code.\n",
    "\n",
    "The write up for this should be no longer than 300 words. Thus we are not expecting much exposition in terms of lit review or setup at this time. We will provide written feedback on your individual assignment. \n",
    "\n",
    "The feedback will be focused on: \n",
    "- **Writing**: Is it clear, have you presented a reasonable rationale for helpfulness and your interpretation of the data? \n",
    "- **Aesthetics**: Have you presented your data in a way that is legible? Can you print or display in a Jupyter Lab notebook data in a useful manner beyond raw `print(len(<object>))`?\n",
    "- **Code**: Is your code clear? That is, is your code modular, with short comments. You can use code from your group project within this so long as there is some additional code that you have written or some way to signify your own contribution to the code. (i.e. you do not have to rewrite the group's code base, only make use of it if warranted)\n",
    "\n",
    "You will also be asked to write an AI declaration. We are not inhibiting your use of AI tools, but we need to understand how deeply these are entwined within your practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67000fa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
